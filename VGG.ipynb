{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab IV",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artursbm/lab-proj-4/blob/master/VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gekrPzTM_dm",
        "colab_type": "code",
        "outputId": "16e73a0f-0d91-4ff6-a243-3a9ecf59faec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1mpFQZYyJXK",
        "colab_type": "code",
        "outputId": "9c4c21a6-f247-458c-8865-2e6f02a26c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class SmallerVGGNet:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        # initialize the model along with the input shape to be\n",
        "        # \"channels last\" and the channels dimension itself\n",
        "        model = Sequential()\n",
        "        inputShape = (height, width, depth)\n",
        "        chanDim = -1\n",
        "\n",
        "        # if we are using \"channels first\", update the input shape\n",
        "        # and channels dimension\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            inputShape = (depth, height, width)\n",
        "            chanDim = 1\n",
        "\n",
        "        # CONV => RELU => POOL\n",
        "        model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "        model.add(Dropout(0.25))\n",
        "        # (CONV => RELU) * 2 => POOL\n",
        "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "        # (CONV => RELU) * 2 => POOL\n",
        "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(axis=chanDim))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "        # first (and only) set of FC => RELU layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1024))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        # softmax classifier\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "\n",
        "        # return the constructed network architecture\n",
        "        return model"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f--1zUlSikAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        " \n",
        "# import the necessary packages\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2oXL5Tqrddq",
        "colab_type": "code",
        "outputId": "7d6d559b-7d0f-49cb-9026-39eb8f109992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBlJqkl6qJ5V",
        "colab_type": "code",
        "outputId": "a937990d-1311-4ef3-c580-15cc610b3006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# initialize the number of epochs to train for, initial learning rate,\n",
        "# batch size, and image dimensions\n",
        "EPOCHS = 100\n",
        "INIT_LR = 1e-3\n",
        "BS = 16\n",
        "IMAGE_DIMS = (96, 96, 3)\n",
        "\n",
        "# initialize the data and labels\n",
        "data = []\n",
        "labels = []\n",
        "dataset=\"gdrive/My Drive/dataset\"\n",
        "# grab the image paths and randomly shuffle them\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = sorted(list(paths.list_images(dataset)))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vzgLhSTwDn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "    # load the image, pre-process it, and store it in the data list\n",
        "    if 'depth' in imagePath:\n",
        "      continue\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "    image = img_to_array(image)\n",
        "    data.append(image)\n",
        "\n",
        "    # extract the class label from the image path and update the\n",
        "    # labels list\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    labels.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoqmFMa-xurt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd05ffb2-9307-45af-d223-e5fb8ccf77d0"
      },
      "source": [
        "# scale the raw pixel intensities to the range [0, 1]\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)\n",
        "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
        "\tdata.nbytes / (1024 * 1000.0)))\n",
        "\n",
        "# binarize the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "# partition the data into training and testing splits using 80% of\n",
        "# the data for training and the remaining 20% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data,\n",
        "\tlabels, test_size=0.2, random_state=42)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] data matrix: 2838.24MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4v0lJ60x0L8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct the image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
        "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhNqfZC1x17L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "3058e163-fd52-41c0-ebe3-30f9a96f190c"
      },
      "source": [
        "# initialize the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
        "\tdepth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit_generator(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tepochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "[INFO] training network...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "657/657 [==============================] - 718s 1s/step - loss: 1.4219 - acc: 0.5774 - val_loss: 3.8067 - val_acc: 0.4399\n",
            "Epoch 2/100\n",
            "657/657 [==============================] - 712s 1s/step - loss: 0.6631 - acc: 0.7910 - val_loss: 0.4302 - val_acc: 0.8531\n",
            "Epoch 3/100\n",
            "657/657 [==============================] - 732s 1s/step - loss: 0.4270 - acc: 0.8611 - val_loss: 0.0539 - val_acc: 0.9821\n",
            "Epoch 4/100\n",
            "657/657 [==============================] - 769s 1s/step - loss: 0.3335 - acc: 0.8890 - val_loss: 2.7963 - val_acc: 0.4399\n",
            "Epoch 5/100\n",
            "657/657 [==============================] - 769s 1s/step - loss: 0.2875 - acc: 0.9068 - val_loss: 0.6046 - val_acc: 0.8208\n",
            "Epoch 6/100\n",
            "657/657 [==============================] - 772s 1s/step - loss: 0.2567 - acc: 0.9180 - val_loss: 0.1474 - val_acc: 0.9517\n",
            "Epoch 7/100\n",
            "657/657 [==============================] - 771s 1s/step - loss: 0.2336 - acc: 0.9236 - val_loss: 0.1027 - val_acc: 0.9688\n",
            "Epoch 8/100\n",
            "657/657 [==============================] - 773s 1s/step - loss: 0.2229 - acc: 0.9286 - val_loss: 0.0510 - val_acc: 0.9814\n",
            "Epoch 9/100\n",
            "657/657 [==============================] - 771s 1s/step - loss: 0.1768 - acc: 0.9420 - val_loss: 1.0012 - val_acc: 0.7827\n",
            "Epoch 10/100\n",
            " 72/657 [==>...........................] - ETA: 10:47 - loss: 0.1151 - acc: 0.9670"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHafyhV1x38x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to disk\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save(args[\"model\"])\n",
        "\n",
        "# save the label binarizer to disk\n",
        "print(\"[INFO] serializing label binarizer...\")\n",
        "f = open(args[\"labelbin\"], \"wb\")\n",
        "f.write(pickle.dumps(lb))\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5-RLKfUx5ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "N = EPOCHS\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.savefig(args[\"plot\"])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}